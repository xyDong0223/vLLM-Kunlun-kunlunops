# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, vllm-kunlun team
# This file is distributed under the same license as the vllm-kunlun
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version:  vllm-kunlun\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-11-10 16:59+0800\n"
"PO-Revision-Date: 2025-07-18 10:09+0800\n"
"Last-Translator: \n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/installation.md:1
msgid "Installation"
msgstr "安装"

#~ msgid "This document describes how to install vllm-kunlun manually."
#~ msgstr "本文档介绍如何手动安装 vllm-kunlun。"

#~ msgid "Requirements"
#~ msgstr "要求"

#~ msgid "OS: Linux"
#~ msgstr "操作系统：Linux"

#~ msgid "Python: >= 3.9, < 3.12"
#~ msgstr "Python：>= 3.9，< 3.12"

#~ msgid "A hardware with Kunlun XPU. It's usually the Atlas 800 A2 series."
#~ msgstr "配备有昇腾XPU的硬件，通常是Atlas 800 A2系列。"

#~ msgid "Software:"
#~ msgstr "软件："

#~ msgid "Software"
#~ msgstr "软件"

#~ msgid "Supported version"
#~ msgstr "支持的版本"

#~ msgid "Note"
#~ msgstr "注释"

#~ msgid "CANN"
#~ msgstr "CANN"

#~ msgid ">= 8.1.RC1"
#~ msgstr ">= 8.1.RC1"

#~ msgid "Required for vllm-kunlun and torch-xpu"
#~ msgstr "vllm-kunlun 和 torch-xpu 必需"

#~ msgid "torch-xpu"
#~ msgstr "torch-xpu"

#~ msgid ">= 2.5.1.post1.dev20250619"
#~ msgstr ">= 2.5.1.post1.dev20250619"

#~ msgid ""
#~ "Required for vllm-kunlun, No need "
#~ "to install manually, it will be "
#~ "auto installed in below steps"
#~ msgstr "vllm-kunlun 必需，无需手动安装，后续步骤会自动安装。"

#~ msgid "torch"
#~ msgstr "torch"

#~ msgid ">= 2.5.1"
#~ msgstr ">= 2.5.1"

#~ msgid "Required for torch-xpu and vllm"
#~ msgstr "torch-xpu 和 vllm 所需"

#~ msgid "You have 2 way to install:"
#~ msgstr "你有两种安装方式："

#~ msgid ""
#~ "**Using pip**: first prepare env "
#~ "manually or via CANN image, then "
#~ "install `vllm-kunlun` using pip."
#~ msgstr "**使用 pip**：首先手动准备环境或通过 CANN 镜像准备环境，然后使用 pip 安装 `vllm-kunlun`。"

#~ msgid ""
#~ "**Using docker**: use the `vllm-kunlun`"
#~ " pre-built docker image directly."
#~ msgstr "**使用 docker**：直接使用 `vllm-kunlun` 预构建的 docker 镜像。"

#~ msgid "Configure a new environment"
#~ msgstr "配置一个新环境"

#~ msgid ""
#~ "Before installing, you need to make "
#~ "sure firmware/driver and CANN are "
#~ "installed correctly, refer to "
#~ "[link](https://kunlun.github.io/docs/sources/kunlun/quick_install.html)"
#~ " for more details."
#~ msgstr ""
#~ "在安装之前，您需要确保固件/驱动和 CANN 已正确安装，更多详情请参考 "
#~ "[链接](https://kunlun.github.io/docs/sources/kunlun/quick_install.html)。"

#~ msgid "Configure hardware environment"
#~ msgstr "配置硬件环境"

#~ msgid ""
#~ "To verify that the Kunlun XPU "
#~ "firmware and driver were correctly "
#~ "installed, run:"
#~ msgstr "要验证 Kunlun XPU 固件和驱动程序是否正确安装，请运行："

#~ msgid ""
#~ "Refer to [Kunlun Environment Setup "
#~ "Guide](https://kunlun.github.io/docs/sources/kunlun/quick_install.html)"
#~ " for more details."
#~ msgstr "更多详情请参考[Kunlun环境搭建指南](https://kunlun.github.io/docs/sources/kunlun/quick_install.html)。"

#~ msgid "Configure software environment"
#~ msgstr "配置软件环境"

#~ msgid "Before using pip"
#~ msgstr "在使用 pip 之前"

#~ msgid ""
#~ "The easiest way to prepare your "
#~ "software environment is using CANN image"
#~ " directly:"
#~ msgstr "最简单的方式是直接使用 CANN 镜像来准备您的软件环境："

#~ msgid "Click here to see \"Install CANN manually\""
#~ msgstr "点击此处查看“手动安装 CANN”"

#~ msgid "You can also install CANN manually:"
#~ msgstr "你也可以手动安装 CANN："

#~ msgid "Before using docker"
#~ msgstr "在使用 docker 之前"

#~ msgid ""
#~ "No more extra step if you are "
#~ "using `vllm-kunlun` prebuilt docker "
#~ "image."
#~ msgstr "如果你使用 `vllm-kunlun` 预构建的 docker 镜像，就无需额外的步骤。"

#~ msgid "Once it's done, you can start to set up `vllm` and `vllm-kunlun`."
#~ msgstr "完成后，你可以开始配置 `vllm` 和 `vllm-kunlun`。"

#~ msgid "Setup vllm and vllm-kunlun"
#~ msgstr "安装 vllm 和 vllm-kunlun"

#~ msgid "Using pip"
#~ msgstr "使用 pip"

#~ msgid "First install system dependencies and config pip mirror:"
#~ msgstr "首先安装系统依赖并配置 pip 镜像："

#~ msgid ""
#~ "**[Optional]** Then config the extra-"
#~ "index of `pip` if you are working"
#~ " on a x86 machine or using "
#~ "torch-xpu dev version:"
#~ msgstr "**[可选]** 如果你在 x86 机器上工作或使用 torch-xpu 开发版，请配置 `pip` 的额外索引："

#~ msgid "Then you can install `vllm` and `vllm-kunlun` from **pre-built wheel**:"
#~ msgstr "然后你可以从**预编译的 wheel 包**安装 `vllm` 和 `vllm-kunlun`："

#~ msgid "Click here to see \"Build from source code\""
#~ msgstr "点击此处查看“从源代码构建”"

#~ msgid "or build from **source code**:"
#~ msgstr "或者从**源代码**构建："

#~ msgid ""
#~ "vllm-kunlun will build custom ops "
#~ "by default. If you don't want to"
#~ " build it, set `COMPILE_CUSTOM_KERNELS=0` "
#~ "environment to disable it."
#~ msgstr ""
#~ "vllm-kunlun 默认会编译自定义算子。如果你不想编译它，可以设置环境变量 "
#~ "`COMPILE_CUSTOM_KERNELS=0` 来禁用。"

#~ msgid ""
#~ "If you are building from v0.7.3-dev "
#~ "and intend to use sleep mode "
#~ "feature, you should set "
#~ "`COMPILE_CUSTOM_KERNELS=1` manually. To build "
#~ "custom ops, gcc/g++ higher than 8 "
#~ "and c++ 17 or higher is required."
#~ " If you're using `pip install -e "
#~ ".` and encourage a torch-xpu "
#~ "version conflict, please install with "
#~ "`pip install --no-build-isolation -e "
#~ ".` to build on system env. If "
#~ "you encounter other problems during "
#~ "compiling, it is probably because "
#~ "unexpected compiler is being used, you"
#~ " may export `CXX_COMPILER` and `C_COMPILER`"
#~ " in env to specify your g++ and"
#~ " gcc locations before compiling."
#~ msgstr ""
#~ "如果你是从 v0.7.3-dev 版本开始构建，并且打算使用休眠模式功能，你需要手动设置 "
#~ "`COMPILE_CUSTOM_KERNELS=1`。构建自定义算子时，要求 gcc/g++ 版本高于 "
#~ "8 且支持 c++ 17 或更高标准。如果你正在使用 `pip "
#~ "install -e .` 并且出现了 torch-xpu "
#~ "版本冲突，请使用 `pip install --no-build-"
#~ "isolation -e .` "
#~ "在系统环境下进行安装。如果在编译过程中遇到其它问题，可能是因为使用了非预期的编译器，你可以在编译前通过环境变量导出 "
#~ "`CXX_COMPILER` 和 `C_COMPILER`，以指定你的 g++ 和 "
#~ "gcc 路径。"

#~ msgid "Using docker"
#~ msgstr "使用 docker"

#~ msgid "You can just pull the **prebuilt image** and run it with bash."
#~ msgstr "你可以直接拉取**预构建镜像**并用 bash 运行它。"

#~ msgid "Click here to see \"Build from Dockerfile\""
#~ msgstr "点击这里查看“从 Dockerfile 构建”"

#~ msgid "or build IMAGE from **source code**:"
#~ msgstr "或从**源代码**构建 IMAGE："

#~ msgid ""
#~ "The default workdir is `/workspace`, "
#~ "vLLM and vLLM Kunlun code are "
#~ "placed in `/vllm-workspace` and "
#~ "installed in [development "
#~ "mode](https://setuptools.pypa.io/en/latest/userguide/development_mode.html)(`pip"
#~ " install -e`) to help developer "
#~ "immediately take place changes without "
#~ "requiring a new installation."
#~ msgstr ""
#~ "默认的工作目录是 `/workspace`，vLLM 和 vLLM Kunlun "
#~ "代码被放置在 `/vllm-"
#~ "workspace`，并以[开发模式](https://setuptools.pypa.io/en/latest/userguide/development_mode.html)（`pip"
#~ " install -e`）安装，以便开发者能够即时生效更改，而无需重新安装。"

#~ msgid "Extra information"
#~ msgstr "额外信息"

#~ msgid "Verify installation"
#~ msgstr "验证安装"

#~ msgid "Create and run a simple inference test. The `example.py` can be like:"
#~ msgstr "创建并运行一个简单的推理测试。`example.py` 可以如下："

#~ msgid "Then run:"
#~ msgstr "然后运行："

#~ msgid "The output will be like:"
#~ msgstr "输出将会像这样："

