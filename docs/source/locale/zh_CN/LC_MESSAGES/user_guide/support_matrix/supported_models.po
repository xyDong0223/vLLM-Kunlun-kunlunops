# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, vllm-kunlun team
# This file is distributed under the same license as the vllm-kunlun
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version:  vllm-kunlun\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-11-10 16:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/user_guide/support_matrix/supported_models.md:1
#, fuzzy
msgid "Supported Models"
msgstr "支持"

#~ msgid "Model Support"
#~ msgstr "模型支持"

#~ msgid "Text-only Language Models"
#~ msgstr "纯文本语言模型"

#~ msgid "Generative Models"
#~ msgstr "生成模型"

#~ msgid "Model"
#~ msgstr "模型"

#~ msgid "Note"
#~ msgstr "注释"

#~ msgid "DeepSeek v3"
#~ msgstr "DeepSeek v3"

#~ msgid "✅"
#~ msgstr "✅"

#~ msgid "DeepSeek R1"
#~ msgstr "DeepSeek R1"

#~ msgid "DeepSeek Distill (Qwen/LLama)"
#~ msgstr "DeepSeek 精炼（Qwen/LLama）"

#~ msgid "Qwen3"
#~ msgstr "Qwen3"

#~ msgid "Qwen3-Moe"
#~ msgstr "Qwen3-Moe"

#~ msgid "Qwen2.5"
#~ msgstr "Qwen2.5"

#~ msgid "QwQ-32B"
#~ msgstr "QwQ-32B"

#~ msgid "LLama3.1/3.2"
#~ msgstr "LLama3.1/3.2"

#~ msgid "Internlm"
#~ msgstr "Internlm"

#~ msgid "Baichuan"
#~ msgstr "百川"

#~ msgid "Phi-4-mini"
#~ msgstr "Phi-4-mini"

#~ msgid "MiniCPM"
#~ msgstr "MiniCPM"

#~ msgid "MiniCPM3"
#~ msgstr "MiniCPM3"

#~ msgid "LLama4"
#~ msgstr "LLama4"

#~ msgid "Mistral"
#~ msgstr "Mistral"

#~ msgid "Need test"
#~ msgstr "需要测试"

#~ msgid "DeepSeek v2.5"
#~ msgstr "DeepSeek v2.5"

#~ msgid "Gemma-2"
#~ msgstr "Gemma-2"

#~ msgid "Mllama"
#~ msgstr "Mllama"

#~ msgid "Gemma-3"
#~ msgstr "Gemma-3"

#~ msgid "❌"
#~ msgstr "❌"

#~ msgid "[#496](https://github.com/vllm-project/vllm-kunlun/issues/496)"
#~ msgstr "[#496](https://github.com/vllm-project/vllm-kunlun/issues/496)"

#~ msgid "ChatGLM"
#~ msgstr "ChatGLM"

#~ msgid "[#554](https://github.com/vllm-project/vllm-kunlun/issues/554)"
#~ msgstr "[#554](https://github.com/vllm-project/vllm-kunlun/issues/554)"

#~ msgid "Pooling Models"
#~ msgstr "池化模型"

#~ msgid "XLM-RoBERTa-based"
#~ msgstr "基于XLM-RoBERTa"

#~ msgid "Molmo"
#~ msgstr "Molmo"

#~ msgid "Multimodal Language Models"
#~ msgstr "多模态语言模型"

#~ msgid "Qwen2-VL"
#~ msgstr "Qwen2-VL"

#~ msgid "Qwen2.5-VL"
#~ msgstr "Qwen2.5-VL"

#~ msgid "LLaVA 1.5"
#~ msgstr "LLaVA 1.5"

#~ msgid "LLaVA 1.6"
#~ msgstr "LLaVA 1.6"

#~ msgid "[#553](https://github.com/vllm-project/vllm-kunlun/issues/553)"
#~ msgstr "[#553](https://github.com/vllm-project/vllm-kunlun/issues/553)"

#~ msgid "InternVL2"
#~ msgstr "InternVL2"

#~ msgid "InternVL2.5"
#~ msgstr "InternVL2.5"

#~ msgid "Qwen2-Audio"
#~ msgstr "Qwen2-Audio"

#~ msgid "LLaVA-Next"
#~ msgstr "LLaVA-Next"

#~ msgid "LLaVA-Next-Video"
#~ msgstr "LLaVA-Next-Video"

#~ msgid "Phi-3-Vison/Phi-3.5-Vison"
#~ msgstr "Phi-3-Vison/Phi-3.5-Vison"

#~ msgid "GLM-4v"
#~ msgstr "GLM-4v"

#~ msgid "Ultravox"
#~ msgstr "Ultravox"

